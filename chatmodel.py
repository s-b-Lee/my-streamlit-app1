# app.py
import base64
import json
from typing import Any, Dict, List, Optional, Tuple

import requests
import streamlit as st

# -----------------------------
# Page
# -----------------------------
st.set_page_config(
    page_title="ì¶”êµ¬ë¯¸ ì±—ë´‡ (ì´ë¯¸ì§€ ì •ì²´ì„± ì„¤ê³„)",
    page_icon="âœ¨",
    layout="wide",
)

# -----------------------------
# Constants
# -----------------------------
PINTEREST_BASE = "https://api.pinterest.com/v5"

STYLE_KEYWORDS = [
    "ì„¸ë ¨ë¨",
    "ìš°ì•„í•¨",
    "ì—¬ì„±ìŠ¤ëŸ¬ì›€",
    "ì¤‘ì„±ì ì¸",
    "ì ˆì œëœ",
    "ê·€ì—¬ì›€",
    "ì²­ìˆœí•¨",
    "ê°•ë ¬í•œ",
    "ì„¹ì‹œí•œ",
    "ë¬´ì±„ìƒ‰ì˜",
    "ì‹œí¬í•¨",
    "ê³ ê¸‰ìŠ¤ëŸ¬ì›€",
    "ì„¹ì‹œí•¨",
    "ëŸ¬ë¸”ë¦¬",
    "ë‹¨ì•„í•œ",
    "ë‹¨ì •í•œ",
]

PRIVACY_NOTICE = (
    "âš ï¸ **ê³ ì§€**: ì´ ì•±ì€ ì˜ë£Œ/ì‹¬ë¦¬ **ì§„ë‹¨**ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
    "ìí•´/ìì‚´ ë“± ìœ„ê¸° ìƒí™©ì´ ìˆê±°ë‚˜ ì•ˆì „ì´ ìš°ë ¤ë˜ë©´, ì¦‰ì‹œ 112/119 ë˜ëŠ” "
    "ê°€ê¹Œìš´ ì‘ê¸‰ì‹¤/ì „ë¬¸ê¸°ê´€ì˜ ë„ì›€ì„ ë°›ìœ¼ì„¸ìš”."
)

PINTEREST_NOTE = (
    "â„¹ï¸ Pinterest APIëŠ” **OAuth Access Token(ë² ì–´ëŸ¬ í† í°)** ê¸°ë°˜ì…ë‹ˆë‹¤. "
    "ë˜í•œ `GET /v5/search/partner/pins`ëŠ” **ë² íƒ€ì´ë©° ëª¨ë“  ì•±ì—ì„œ ì‚¬ìš© ë¶ˆê°€**ì¼ ìˆ˜ ìˆì–´ìš”. "
    "ì‚¬ìš© ë¶ˆê°€(403 ë“±)ë©´ ì•±ì—ì„œ ì•ˆë‚´ ë¬¸êµ¬ê°€ í‘œì‹œë©ë‹ˆë‹¤."
)

# ëª¨ë¸ í›„ë³´: ì ‘ê·¼ ë¶ˆê°€ ëª¨ë¸ì´ë©´ ìë™ìœ¼ë¡œ ë‹¤ìŒ í›„ë³´ë¡œ ë„˜ì–´ê°
MODEL_CANDIDATES_DEFAULT = ["gpt-4o-mini", "gpt-4.1-mini", "gpt-4o"]

# ì´ë¯¸ì§€ ìƒì„± í›„ë³´(ê¶Œí•œ/ì •ì±…ì— ë”°ë¼ ì‹¤íŒ¨í•  ìˆ˜ ìˆì–´ fallback ì²˜ë¦¬)
IMAGE_MODEL_CANDIDATES_DEFAULT = ["gpt-image-1"]


# -----------------------------
# Session State
# -----------------------------
def init_state():
    defaults = {
        "style_messages": [],
        "style_inputs": {
            "keywords": [],
            "text_like": "",
            "text_dislike": "",
            "text_constraints": "",
            "uploaded_image_bytes": None,
            "uploaded_image_name": None,
            "uploaded_image_analysis": None,
        },
        "style_report": None,
        "pinterest_cache": {},
        "pinterest_last_term": "",
        "pinterest_suggested_queries": [],
        "pinterest_negative_terms": [],
        "working_model": None,
        "working_image_model": None,
        "outfit_images": [],  # [{title, b64, prompt}]
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v


init_state()


# -----------------------------
# OpenAI REST helpers (Chat Completions) with fallback
# -----------------------------
def _post_chat_completions(api_key: str, payload: Dict[str, Any], timeout: int = 90) -> requests.Response:
    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    return requests.post(url, headers=headers, json=payload, timeout=timeout, stream=bool(payload.get("stream")))


def _is_model_access_error(msg: str) -> bool:
    if not msg:
        return False
    m = msg.lower()
    return (
        "model" in m
        and ("does not exist" in m or "do not have access" in m or "not found" in m or "permission" in m)
    )


def _try_models(api_key: str, build_payload_fn, model_candidates: List[str], timeout: int) -> Tuple[str, Dict[str, Any]]:
    last_err_msg = ""
    for model in model_candidates:
        payload = build_payload_fn(model)
        try:
            r = _post_chat_completions(api_key, payload, timeout=timeout)
            if r.status_code == 200:
                return model, r.json()

            try:
                err = r.json()
                last_err_msg = err.get("error", {}).get("message", r.text)
            except Exception:
                last_err_msg = r.text

            if _is_model_access_error(last_err_msg):
                continue
            raise RuntimeError(last_err_msg)

        except requests.exceptions.Timeout:
            raise RuntimeError("ìš”ì²­ ì‹œê°„ì´ ì´ˆê³¼ëì–´ìš”. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        except requests.exceptions.RequestException:
            raise RuntimeError("ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

    raise RuntimeError(
        "ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. (ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œ/ì¡°ì§ ì •ì±…/í‚¤ ì„¤ì •ì„ í™•ì¸í•´ ì£¼ì„¸ìš”)\n"
        f"- ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_err_msg}"
    )


def openai_stream_chat_with_fallback(
    api_key: str,
    system_prompt: str,
    messages: List[Dict[str, Any]],
    model_candidates: List[str],
    temperature: float = 0.6,
) -> Tuple[str, str]:
    used_model = st.session_state.get("working_model")
    candidates = [used_model] + model_candidates if used_model else model_candidates

    def build_payload(model: str) -> Dict[str, Any]:
        return {
            "model": model,
            "temperature": temperature,
            "stream": True,
            "messages": [{"role": "system", "content": system_prompt}] + messages,
        }

    last_err_msg = ""
    for model in candidates:
        payload = build_payload(model)
        placeholder = st.empty()
        full_text = ""

        try:
            with _post_chat_completions(api_key, payload, timeout=120) as r:
                if r.status_code != 200:
                    try:
                        err = r.json()
                        last_err_msg = err.get("error", {}).get("message", r.text)
                    except Exception:
                        last_err_msg = r.text

                    if _is_model_access_error(last_err_msg):
                        continue
                    raise RuntimeError(last_err_msg)

                for line in r.iter_lines(decode_unicode=True):
                    if not line:
                        continue
                    if line.startswith("data: "):
                        data = line[len("data: ") :].strip()
                        if data == "[DONE]":
                            break
                        try:
                            j = json.loads(data)
                            delta = j["choices"][0]["delta"].get("content", "")
                            if delta:
                                full_text += delta
                                placeholder.markdown(full_text)
                        except Exception:
                            continue

                st.session_state["working_model"] = model
                return full_text, model

        except requests.exceptions.Timeout:
            raise RuntimeError("ìš”ì²­ ì‹œê°„ì´ ì´ˆê³¼ëì–´ìš”. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        except requests.exceptions.RequestException:
            raise RuntimeError("ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

    raise RuntimeError("ìŠ¤íŠ¸ë¦¬ë°ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”.\n" f"- ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_err_msg}")


def openai_json_with_fallback(
    api_key: str,
    system_prompt: str,
    user_prompt: str,
    model_candidates: List[str],
    temperature: float = 0.2,
    timeout: int = 60,
) -> Tuple[Dict[str, Any], str]:
    used_model = st.session_state.get("working_model")
    candidates = [used_model] + model_candidates if used_model else model_candidates

    def build_payload(model: str) -> Dict[str, Any]:
        return {
            "model": model,
            "temperature": temperature,
            "stream": False,
            "response_format": {"type": "json_object"},
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
        }

    model, resp = _try_models(api_key, build_payload, candidates, timeout=timeout)
    st.session_state["working_model"] = model
    content = resp["choices"][0]["message"]["content"]
    return json.loads(content), model


def openai_vision_analyze_style_with_fallback(
    api_key: str,
    image_bytes: bytes,
    allowed_keywords: List[str],
    model_candidates: List[str],
) -> Tuple[Dict[str, Any], str]:
    b64 = base64.b64encode(image_bytes).decode("utf-8")
    data_url = f"data:image/jpeg;base64,{b64}"

    system_prompt = (
        "ë‹¹ì‹ ì€ 'ì¶”êµ¬ë¯¸(ì´ë¯¸ì§€ ì •ì²´ì„±)' ë¶„ì„ê°€ì…ë‹ˆë‹¤. "
        "ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ë¥¼ ë³´ê³ , ì£¼ì–´ì§„ í‚¤ì›Œë“œ í›„ë³´ ì¤‘ì—ì„œë§Œ "
        "ì´ë¯¸ì§€ì˜ ë¶„ìœ„ê¸°/ìŠ¤íƒ€ì¼ì— í•´ë‹¹í•˜ëŠ” í‚¤ì›Œë“œë¥¼ ê³¨ë¼ì£¼ì„¸ìš”. "
        "ê³¼ì¥í•˜ì§€ ë§ê³ , ë³´ì´ëŠ” ê·¼ê±°ë¥¼ ì§§ê²Œ ì„¤ëª…í•˜ì„¸ìš”. "
        "ê°œì¸ ì‹ë³„(ëˆ„êµ¬ì¸ì§€, ë‚˜ì´ ì¶”ì • ë“±)ì€ í•˜ì§€ ë§ˆì„¸ìš”. "
        "ë°˜ë“œì‹œ JSONìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”."
    )

    user_message = {
        "role": "user",
        "content": [
            {
                "type": "text",
                "text": (
                    f"í—ˆìš© í‚¤ì›Œë“œ í›„ë³´:\n{allowed_keywords}\n\n"
                    "ìš”ì²­:\n"
                    "1) í›„ë³´ ì¤‘ 3~7ê°œ í‚¤ì›Œë“œë¥¼ ì„ íƒ\n"
                    "2) ê·¼ê±°ë¥¼ í•œ ë‹¨ë½ìœ¼ë¡œ ì§§ê²Œ\n"
                    "3) ì´ë¯¸ì§€ê°€ ì¶”êµ¬ë¯¸ ë¶„ì„ì— ë¶€ì ì ˆ/ì• ë§¤í•˜ë©´ ê²½ê³ ë¬¸(warnings)ì— í•œ ì¤„\n\n"
                    "ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ:\n"
                    '{ "keywords": [...], "rationale": "...", "warnings": "..." }'
                ),
            },
            {"type": "image_url", "image_url": {"url": data_url}},
        ],
    }

    used_model = st.session_state.get("working_model")
    candidates = [used_model] + model_candidates if used_model else model_candidates

    def build_payload(model: str) -> Dict[str, Any]:
        return {
            "model": model,
            "temperature": 0.2,
            "stream": False,
            "response_format": {"type": "json_object"},
            "messages": [
                {"role": "system", "content": system_prompt},
                user_message,
            ],
        }

    model, resp = _try_models(api_key, build_payload, candidates, timeout=90)
    st.session_state["working_model"] = model
    content = resp["choices"][0]["message"]["content"]
    return json.loads(content), model


# -----------------------------
# OpenAI Images API (optional) with fallback
# -----------------------------
def _post_images(api_key: str, payload: Dict[str, Any], timeout: int = 120) -> requests.Response:
    # âœ… ì˜¤ë¥˜ ìˆ˜ì •: 404 ì›ì¸ = ì˜ëª»ëœ ì—”ë“œí¬ì¸íŠ¸
    #   ì˜¬ë°”ë¥¸ ì´ë¯¸ì§€ ìƒì„± ì—”ë“œí¬ì¸íŠ¸ë¡œ ë³€ê²½
    url = "https://api.openai.com/v1/images/generations"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    return requests.post(url, headers=headers, json=payload, timeout=timeout)


def _is_image_model_access_error(msg: str) -> bool:
    if not msg:
        return False
    m = msg.lower()
    return ("model" in m) and ("does not exist" in m or "do not have access" in m or "not found" in m)


def generate_outfit_image_with_fallback(
    api_key: str,
    prompt: str,
    image_model_candidates: List[str],
    size: str = "1024x1024",
) -> Tuple[str, str]:
    """
    Returns (b64_png, used_image_model)
    """
    used_model = st.session_state.get("working_image_model")
    candidates = [used_model] + image_model_candidates if used_model else image_model_candidates

    last_err = ""
    for model in candidates:
        payload = {
            "model": model,
            "prompt": prompt,
            "size": size,
            # b64_json ì‘ë‹µì„ ê¸°ëŒ€ (ê¸°ë³¸)
        }
        try:
            r = _post_images(api_key, payload, timeout=180)
            if r.status_code == 200:
                j = r.json()
                b64_png = j["data"][0].get("b64_json")
                if not b64_png:
                    raise RuntimeError("ì´ë¯¸ì§€ ì‘ë‹µì—ì„œ b64_jsonì„ ì°¾ì§€ ëª»í–ˆì–´ìš”.")
                st.session_state["working_image_model"] = model
                return b64_png, model

            try:
                err = r.json()
                last_err = err.get("error", {}).get("message", r.text)
            except Exception:
                last_err = r.text

            if _is_image_model_access_error(last_err):
                continue
            raise RuntimeError(last_err)

        except requests.exceptions.Timeout:
            raise RuntimeError("ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ ì‹œê°„ì´ ì´ˆê³¼ëì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        except requests.exceptions.RequestException:
            raise RuntimeError("ì´ë¯¸ì§€ ìƒì„± ì¤‘ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.")

    raise RuntimeError(f"ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ìš”.\n- ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_err}")


# -----------------------------
# Pinterest helpers
# -----------------------------
def pinterest_headers(access_token: str) -> Dict[str, str]:
    return {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json",
        "Accept": "application/json",
    }


def pinterest_best_image_url(media: Optional[Dict[str, Any]]) -> Optional[str]:
    if not media or not isinstance(media, dict):
        return None
    images = media.get("images")
    if not isinstance(images, dict):
        return None
    for key in ["600x", "400x300", "1200x", "150x150"]:
        if key in images and isinstance(images[key], dict) and images[key].get("url"):
            return images[key]["url"]
    for v in images.values():
        if isinstance(v, dict) and v.get("url"):
            return v["url"]
    return None


def pinterest_search_partner_pins(
    access_token: str,
    term: str,
    country_code: str = "KR",
    locale: str = "ko-KR",
    limit: int = 12,
    bookmark: Optional[str] = None,
) -> Dict[str, Any]:
    url = f"{PINTEREST_BASE}/search/partner/pins"
    params = {
        "term": term,
        "country_code": country_code,
        "locale": locale,
        "limit": max(1, min(limit, 50)),
    }
    if bookmark:
        params["bookmark"] = bookmark

    r = requests.get(url, headers=pinterest_headers(access_token), params=params, timeout=30)
    if r.status_code != 200:
        try:
            err = r.json()
        except Exception:
            err = {"message": r.text}
        raise RuntimeError(f"Pinterest API ì˜¤ë¥˜ ({r.status_code}): {err}")
    return r.json()


# -----------------------------
# UI helpers
# -----------------------------
def render_color_swatches(colors: List[Dict[str, str]], title: str = "ì»¬ëŸ¬ íŒ”ë ˆíŠ¸"):
    """
    colors: [{"name": "...", "hex": "#AABBCC"}, ...]
    """
    if not colors:
        st.caption("í‘œì‹œí•  ì»¬ëŸ¬ ì •ë³´ê°€ ì—†ì–´ìš”.")
        return

    st.markdown(f"**{title}**")
    cols = st.columns(min(6, len(colors)))
    for i, c in enumerate(colors):
        name = (c or {}).get("name", "") or "color"
        hx = (c or {}).get("hex", "") or "#CCCCCC"
        with cols[i % len(cols)]:
            st.markdown(
                f"""
                <div style="border:1px solid #e5e7eb; border-radius:14px; padding:10px;">
                  <div style="height:44px; border-radius:10px; background:{hx};"></div>
                  <div style="margin-top:8px; font-weight:700;">{name}</div>
                  <div style="font-size:12px; opacity:0.75;">{hx}</div>
                </div>
                """,
                unsafe_allow_html=True,
            )


# -----------------------------
# Prompts
# -----------------------------
def style_report_prompt(style_inputs: Dict[str, Any]) -> Tuple[str, str]:
    system_prompt = (
        "ë‹¹ì‹ ì€ 'ì¶”êµ¬ë¯¸ ë„ìš°ë¯¸'ì…ë‹ˆë‹¤. "
        "ì‚¬ìš©ìì˜ ì„ íƒ í‚¤ì›Œë“œ/í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ë¶„ì„(ì„ íƒ)ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”êµ¬ë¯¸ ë¦¬í¬íŠ¸ì™€ ì‹¤ì²œ ê°€ì´ë“œë¥¼ ìƒì„±í•˜ì„¸ìš”. "
        "ë¸Œëœë“œ/ì œí’ˆ ì¶”ì²œ ê¸ˆì§€(ë°©í–¥ì„±ë§Œ). "
        "ê³¼ì¥í•˜ì§€ ë§ê³  êµ¬ì¡°ì ìœ¼ë¡œ. ë°˜ë“œì‹œ JSONìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”.\n\n"
        "ì¤‘ìš”:\n"
        "- best_contexts(ì–´ìš¸ë¦¬ëŠ” ìƒí™©)ëŠ” ì ˆëŒ€ 'x' ê°™ì€ ìë¦¬í‘œì‹œìê°€ ì•„ë‹ˆë¼, í•œêµ­ì–´ë¡œ êµ¬ì²´ì ì¸ ìƒí™© 4~7ê°œë¥¼ ì œì‹œí•˜ì„¸ìš”.\n"
        "- color_palette/avoid_colorsëŠ” ê° ìƒ‰ì„ name + hex(#RRGGBB)ë¡œ ì œê³µí•˜ì„¸ìš”.\n"
        "- outfit_examplesëŠ” 3ê°œ ì´ìƒ ì œê³µ(ê°ê° 'íƒ€ì´í‹€', 'ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸', 'í¬ì¸íŠ¸', 'ì¶”ì²œ íŒ”ë ˆíŠ¸ ìƒ‰(ìœ„ íŒ”ë ˆíŠ¸ì—ì„œ ì°¸ì¡°)' í¬í•¨).\n"
    )

    user_prompt = {
        "selected_keywords": style_inputs.get("keywords", []),
        "text_like": style_inputs.get("text_like", ""),
        "text_dislike": style_inputs.get("text_dislike", ""),
        "text_constraints": style_inputs.get("text_constraints", ""),
        "uploaded_image_analysis": style_inputs.get("uploaded_image_analysis"),
        "output_schema": {
            "type_name_ko": "",
            "type_name_en": "",
            "identity_one_liner": "",
            "core_keywords": [],
            "mini_report": {
                "mood_summary": "",
                "impression": "",
                "best_contexts": ["êµ¬ì²´ì ì¸ ìƒí™©1", "êµ¬ì²´ì ì¸ ìƒí™©2"],
                "watch_out": "",
                "maintenance_difficulty": "ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ ì¤‘ í•˜ë‚˜",
            },
            "apply_strategy": "",
            "practice_guide": {
                "makeup": {"base": "", "points": {"eyes": "", "lips": ""}, "avoid": ""},
                "fashion": {
                    "silhouette": "",
                    "color_palette": [{"name": "charcoal", "hex": "#2E2E2E"}],
                    "avoid_colors": [{"name": "neon green", "hex": "#39FF14"}],
                    "top5_items": [],
                },
                "behavior_lifestyle": {"gesture_tone": "", "speech_manner": "", "daily_habits": []},
            },
            "outfit_examples": [
                {
                    "title": "",
                    "items": ["", "", ""],
                    "point": "",
                    "palette_refs": ["charcoal", "ivory"],
                }
            ],
        },
        "rules": [
            "best_contextsëŠ” ìµœì†Œ 4ê°œ ì´ìƒ, êµ¬ì²´ì ìœ¼ë¡œ",
            "ë¸Œëœë“œ/ì œí’ˆëª… ê¸ˆì§€",
            "ìƒ‰ì€ ë°˜ë“œì‹œ hexë¡œ",
        ],
    }

    return system_prompt, json.dumps(user_prompt, ensure_ascii=False)


def pinterest_query_expander_prompt(chosen_keywords: List[str]) -> Tuple[str, str]:
    system_prompt = (
        "ë‹¹ì‹ ì€ Pinterest ê²€ìƒ‰ì–´ ì„¤ê³„ìì…ë‹ˆë‹¤. "
        "ì‚¬ìš©ìê°€ ì„ íƒí•œ ì¶”êµ¬ë¯¸ í‚¤ì›Œë“œë¡œ 'ì‚¬ëŒ(ì¸ë¬¼) ì´ë¯¸ì§€'ê°€ ì˜ ë‚˜ì˜¤ëŠ” ê²€ìƒ‰ì–´ë¥¼ ë§Œë“ ë‹¤. "
        "Pinterest ê²€ìƒ‰ì— ê°•í•œ ì§§ì€ ì¿¼ë¦¬ë¡œ 3~6ê°œë¥¼ ì œì•ˆí•˜ë¼. "
        "í•œêµ­ì–´/ì˜ì–´ í˜¼í•© ê°€ëŠ¥. "
        "ë°˜ë“œì‹œ JSONìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”."
    )
    user_prompt = (
        f"í‚¤ì›Œë“œ: {chosen_keywords}\n\n"
        'JSON ìŠ¤í‚¤ë§ˆ: {"queries":[...], "negative_terms":[...], "note":"..."}\n'
        "- queriesëŠ” 3~6ê°œ, ê° 2~6ë‹¨ì–´\n"
        "- ì‚¬ëŒ/íŒ¨ì…˜/ë£©/ë©”ì´í¬ì—… ì¤‘ì‹¬(ì˜ˆ: 'neutral chic outfit', 'clean girl makeup')"
    )
    return system_prompt, user_prompt


def style_chat_system_prompt() -> str:
    return """
ë‹¹ì‹ ì€ 'ì¶”êµ¬ë¯¸(ì´ë¯¸ì§€ ì •ì²´ì„±) ì½”ì¹˜'ì…ë‹ˆë‹¤.

ì›ì¹™:
- ë‘ê´„ì‹, ê³¼ì¥ ê¸ˆì§€, ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆ ìœ„ì£¼
- ë¸Œëœë“œ/ì œí’ˆëª… ì¶”ì²œ ê¸ˆì§€(ë°©í–¥ì„±, ê¸°ì¤€, ì²´í¬ë¦¬ìŠ¤íŠ¸ë§Œ)
- ì‚¬ìš©ìê°€ ê³ ë¥¸ í‚¤ì›Œë“œ(5~10ê°œ)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬
- ì‚¬ìš©ìê°€ ì‹«ë‹¤ê³  í•œ ìš”ì†Œ/ì œì•½ì¡°ê±´ì„ ìš°ì„  ë°˜ì˜
- ë‹µë³€ì€ í•œêµ­ì–´, ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ(ë¬¸ë‹¨ 3~6ê°œ)
- í•„ìš”í•  ë•Œë§Œ ì§ˆë¬¸ 1ê°œ

ì¶œë ¥ ê°€ì´ë“œ:
1) í•œ ì¤„ ìš”ì•½(í˜„ì¬ ì¶”êµ¬ë¯¸ ë°©í–¥)
2) í•µì‹¬ ê¸°ì¤€ 3ê°œ(ë¬´ì—‡ì„ í•˜ë©´ ê·¸ ë¶„ìœ„ê¸°ê°€ ìœ ì§€ë˜ëŠ”ì§€)
3) ë©”ì´í¬ì—…/íŒ¨ì…˜/íƒœë„ ì¤‘ 2~3ê°œ ì˜ì—­ì—ì„œ ë°”ë¡œ ì ìš© íŒ
4) ë§ˆì§€ë§‰ì— ì§ˆë¬¸ 1ê°œ(ì •ë°€ë„ ì˜¬ë¦´ ë•Œë§Œ)
""".strip()


# -----------------------------
# Sidebar
# -----------------------------
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    openai_key = st.text_input("OpenAI API Key", type="password", value="")
    pinterest_token = st.text_input("Pinterest Access Token (Bearer)", type="password", value="")
    st.caption(PINTEREST_NOTE)

    st.divider()

    raw_models = st.text_input(
        "OpenAI ëª¨ë¸ í›„ë³´(ì‰¼í‘œë¡œ êµ¬ë¶„, ì•ë¶€í„° ìš°ì„  ì‹œë„)",
        value=", ".join(MODEL_CANDIDATES_DEFAULT),
    )
    model_candidates = [m.strip() for m in raw_models.split(",") if m.strip()] or MODEL_CANDIDATES_DEFAULT

    raw_image_models = st.text_input(
        "ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ í›„ë³´(ì‰¼í‘œë¡œ êµ¬ë¶„)",
        value=", ".join(IMAGE_MODEL_CANDIDATES_DEFAULT),
        help="ì˜ˆì‹œ ì½”ë”” ì´ë¯¸ì§€ë¥¼ â€˜ì‹œê°í™”â€™ ë²„íŠ¼ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤. ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìœ¼ë©´ ì‹¤íŒ¨í•  ìˆ˜ ìˆì–´ìš”.",
    )
    image_model_candidates = [m.strip() for m in raw_image_models.split(",") if m.strip()] or IMAGE_MODEL_CANDIDATES_DEFAULT

    img_size = st.selectbox("ì½”ë”” ì´ë¯¸ì§€ í¬ê¸°", ["1024x1024", "512x512"], index=0)

    if st.button("ğŸ§¹ ì´ˆê¸°í™”", use_container_width=True):
        st.session_state["style_messages"] = []
        st.session_state["style_report"] = None
        st.session_state["outfit_images"] = []
        st.session_state["pinterest_cache"] = {}
        st.session_state["pinterest_last_term"] = ""
        st.session_state["pinterest_suggested_queries"] = []
        st.session_state["pinterest_negative_terms"] = []
        st.session_state["working_model"] = None
        st.session_state["working_image_model"] = None
        st.session_state["style_inputs"] = {
            "keywords": [],
            "text_like": "",
            "text_dislike": "",
            "text_constraints": "",
            "uploaded_image_bytes": None,
            "uploaded_image_name": None,
            "uploaded_image_analysis": None,
        }
        st.success("ì´ˆê¸°í™” ì™„ë£Œ!")

    st.divider()
    st.markdown(PRIVACY_NOTICE)

# -----------------------------
# Main
# -----------------------------
st.title("âœ¨ ì¶”êµ¬ë¯¸ ì±—ë´‡")
st.caption("í‚¤ì›Œë“œ(5~10ê°œ) + ì¶”ê°€ ì •ë³´ + (ì„ íƒ) ì´ë¯¸ì§€ ë¶„ì„ + Pinterest ì°¸ê³  + ì˜ˆì‹œ ì½”ë”” ì‹œê°í™”")

# 1) í‚¤ì›Œë“œ ì„ íƒ (5~10)
st.subheader("1) ë¬´ë“œ/ìŠ¤íƒ€ì¼ ì„ íƒ (5~10ê°œ)")
selected = st.multiselect(
    "ëŒë¦¬ëŠ” í‚¤ì›Œë“œë¥¼ ê³¨ë¼ì£¼ì„¸ìš”",
    STYLE_KEYWORDS,
    default=st.session_state["style_inputs"].get("keywords", []),
    max_selections=10,
)
st.session_state["style_inputs"]["keywords"] = selected
st.caption("â€» ìµœì†Œ 5ê°œ, ìµœëŒ€ 10ê°œë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")

# 2) ì¶”ê°€ ì •ë³´ ì…ë ¥
st.subheader("2) ì¶”ê°€ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
col_a, col_b, col_c = st.columns(3)
with col_a:
    st.session_state["style_inputs"]["text_like"] = st.text_area(
        "ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” ìŠ¤íƒ€ì¼ì„ êµ¬ì²´ì ìœ¼ë¡œ ì ì–´ë³´ì•„ìš”.",
        value=st.session_state["style_inputs"].get("text_like", ""),
        placeholder="ì˜ˆ: í¸í•´ ë³´ì´ëŠ”ë° ì„¸ë ¨ëìœ¼ë©´ / í”¼ë¶€ í‘œí˜„ì€ ê¹¨ë—í•˜ê²Œ",
        height=120,
    )
with col_b:
    st.session_state["style_inputs"]["text_dislike"] = st.text_area(
        "ì´ëŸ° ëŠë‚Œì€ ì‹«ì–´ìš”",
        value=st.session_state["style_inputs"].get("text_dislike", ""),
        placeholder="ì˜ˆ: ë„ˆë¬´ ê¾¸ë¯¼ ëŠë‚Œ / ê³¼í•œ í„",
        height=120,
    )
with col_c:
    st.session_state["style_inputs"]["text_constraints"] = st.text_area(
        "í˜„ì‹¤ ì œì•½/ì¡°ê±´(ì„ íƒ)",
        value=st.session_state["style_inputs"].get("text_constraints", ""),
        placeholder="ì˜ˆ: í•™êµì—ì„œ ë¬´ë‚œí•´ì•¼ í•¨ / ì˜ˆì‚° ì œí•œ / ê´€ë¦¬ ì‹œê°„ ì ìŒ",
        height=120,
    )

# 3) ì´ë¯¸ì§€ ì—…ë¡œë“œ â€” ì¶”êµ¬ë¯¸ ë¶„ìœ„ê¸° ë¶„ì„
st.subheader("3) (ì„ íƒ) ì´ë¯¸ì§€ ì—…ë¡œë“œ â€” ì¶”êµ¬ë¯¸ ë¶„ìœ„ê¸° ë¶„ì„")
up = st.file_uploader("ì¢‹ë‹¤ê³  ëŠê¼ˆë˜ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì˜¬ë ¤ì£¼ì„¸ìš” (jpg/png)", type=["jpg", "jpeg", "png"])
if up is not None:
    img_bytes = up.read()
    st.session_state["style_inputs"]["uploaded_image_bytes"] = img_bytes
    st.session_state["style_inputs"]["uploaded_image_name"] = up.name
    st.image(img_bytes, caption=f"ì—…ë¡œë“œ: {up.name}", use_container_width=True)

    if st.button("ğŸ§  ì—…ë¡œë“œ ì´ë¯¸ì§€ë¡œ ì¶”êµ¬ë¯¸ í‚¤ì›Œë“œ ì¶”ì •", use_container_width=True):
        if not openai_key:
            st.warning("OpenAI API Keyë¥¼ ì…ë ¥í•˜ë©´ ì´ë¯¸ì§€ ë¶„ì„ì„ í•  ìˆ˜ ìˆì–´ìš”.")
        else:
            with st.spinner("ì´ë¯¸ì§€ ë¶„ìœ„ê¸°ë¥¼ ë¶„ì„ ì¤‘..."):
                try:
                    analysis, used_model = openai_vision_analyze_style_with_fallback(
                        openai_key,
                        img_bytes,
                        STYLE_KEYWORDS,
                        model_candidates=model_candidates,
                    )
                    st.session_state["style_inputs"]["uploaded_image_analysis"] = analysis
                    st.success(f"ì´ë¯¸ì§€ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì • ì™„ë£Œ! (ì‚¬ìš© ëª¨ë¸: {used_model})")
                except Exception as e:
                    st.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}")

if st.session_state["style_inputs"].get("uploaded_image_analysis"):
    a = st.session_state["style_inputs"]["uploaded_image_analysis"]
    st.markdown("#### ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼(ì°¸ê³ )")
    st.markdown(f"- ì¶”ì • í‚¤ì›Œë“œ: **{', '.join(a.get('keywords', []))}**")
    if a.get("rationale"):
        st.caption(a["rationale"])
    if a.get("warnings"):
        st.warning(a["warnings"])

    if st.button("â• ì´ë¯¸ì§€ í‚¤ì›Œë“œë¥¼ ì„ íƒ í‚¤ì›Œë“œì— í•©ì¹˜ê¸°", use_container_width=True):
        merged = list(dict.fromkeys(st.session_state["style_inputs"]["keywords"] + a.get("keywords", [])))
        st.session_state["style_inputs"]["keywords"] = merged[:10]
        st.rerun()

st.divider()

# Pinterest (ì„ íƒ)
st.subheader("ğŸ§· Pinterest ì°¸ê³  ì´ë¯¸ì§€(ì¸ë¬¼ ì´ë¯¸ì§€ ê²€ìƒ‰)")
st.caption("ì„ íƒí•œ ì¶”êµ¬ë¯¸ í‚¤ì›Œë“œë¡œ Pinterestì—ì„œ ì°¸ê³  ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤(ê¶Œí•œ/í† í° í•„ìš”).")

if not pinterest_token:
    st.info("ì‚¬ì´ë“œë°”ì— Pinterest Access Tokenì„ ì…ë ¥í•˜ë©´ Pinterest ì´ë¯¸ì§€ë¥¼ ë¶™ì¼ ìˆ˜ ìˆì–´ìš”.")
else:
    colp1, colp2 = st.columns([2, 1])
    with colp1:
        manual_term = st.text_input("ì§ì ‘ ê²€ìƒ‰ì–´(ì„ íƒ)", value=st.session_state.get("pinterest_last_term", ""))
    with colp2:
        st.write("")
        st.write("")
        auto_expand = st.checkbox("ğŸ¤– AIë¡œ ê²€ìƒ‰ì–´ ì¶”ì²œ", value=True)

    if auto_expand and openai_key and st.session_state["style_inputs"]["keywords"]:
        if st.button("ğŸ” ê²€ìƒ‰ì–´ ì¶”ì²œ ë§Œë“¤ê¸°", use_container_width=True):
            try:
                spx, upx = pinterest_query_expander_prompt(st.session_state["style_inputs"]["keywords"])
                qq, used_model = openai_json_with_fallback(
                    openai_key,
                    spx,
                    upx,
                    model_candidates=model_candidates,
                    temperature=0.2,
                    timeout=60,
                )
                st.session_state["pinterest_suggested_queries"] = (qq.get("queries", []) or [])[:6]
                st.session_state["pinterest_negative_terms"] = (qq.get("negative_terms", []) or [])[:6]
                st.success(f"ì¶”ì²œ ê²€ìƒ‰ì–´ ìƒì„± ì™„ë£Œ! (ì‚¬ìš© ëª¨ë¸: {used_model})")
            except Exception as e:
                st.error(f"ê²€ìƒ‰ì–´ ì¶”ì²œ ì˜¤ë¥˜: {e}")

    suggested_queries = st.session_state.get("pinterest_suggested_queries", [])
    negative_terms = st.session_state.get("pinterest_negative_terms", [])

    if suggested_queries:
        st.markdown("**ì¶”ì²œ ê²€ìƒ‰ì–´:** " + " Â· ".join([f"`{q}`" for q in suggested_queries]))
    if negative_terms:
        st.caption("ì œì™¸(ì°¸ê³ ): " + ", ".join([f"`{q}`" for q in negative_terms]))

    term_to_search = manual_term.strip()
    if not term_to_search and suggested_queries:
        term_to_search = suggested_queries[0]

    cols_btn = st.columns([1, 1, 2])
    with cols_btn[0]:
        do_search = st.button("ğŸ“Œ Pinterest ê²€ìƒ‰", use_container_width=True)
    with cols_btn[1]:
        clear_cache = st.button("ğŸ§½ Pinterest ìºì‹œ ë¹„ìš°ê¸°", use_container_width=True)
    with cols_btn[2]:
        st.caption("â€» /search/partner/pinsëŠ” ë² íƒ€ë¼ 403ì´ë©´ ì‚¬ìš© ë¶ˆê°€ ì•ˆë‚´ê°€ ë‚˜ì˜µë‹ˆë‹¤.")

    if clear_cache:
        st.session_state["pinterest_cache"] = {}
        st.success("ìºì‹œë¥¼ ë¹„ì› ì–´ìš”!")

    pins = []
    if do_search:
        if not term_to_search:
            st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ê±°ë‚˜(ë˜ëŠ” ì¶”ì²œ ê²€ìƒ‰ì–´ ìƒì„±) ì§„í–‰í•´ ì£¼ì„¸ìš”.")
        else:
            st.session_state["pinterest_last_term"] = term_to_search
            cache = st.session_state["pinterest_cache"]
            if term_to_search in cache:
                pins = cache[term_to_search]
            else:
                with st.spinner("Pinterestì—ì„œ í•€ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                    try:
                        data = pinterest_search_partner_pins(
                            pinterest_token,
                            term_to_search,
                            country_code="KR",
                            locale="ko-KR",
                            limit=12,
                        )
                        items = data.get("items", []) or []
                        norm = []
                        for it in items:
                            media = it.get("media") or {}
                            img_url = pinterest_best_image_url(media)
                            norm.append(
                                {
                                    "id": it.get("id"),
                                    "title": it.get("title") or "",
                                    "description": it.get("description") or "",
                                    "link": it.get("link") or "",
                                    "img": img_url,
                                    "alt_text": it.get("alt_text") or "",
                                }
                            )
                        pins = norm
                        cache[term_to_search] = pins
                        st.session_state["pinterest_cache"] = cache
                    except Exception as e:
                        st.error(
                            "Pinterest APIì—ì„œ í•€ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆì–´ìš”.\n\n"
                            f"- ì‚¬ìœ : {e}\n\n"
                            "ê°€ëŠ¥í•œ ì›ì¸:\n"
                            "- ì´ ì•±/í† í°ì´ `GET /v5/search/partner/pins`(ë² íƒ€) ê¶Œí•œì´ ì—†ìŒ\n"
                            "- í† í° ë§Œë£Œ/ìŠ¤ì½”í”„ ë¶€ì¡±\n"
                            "- ë ˆì´íŠ¸ë¦¬ë°‹/ë„¤íŠ¸ì›Œí¬\n"
                        )

    if not pins and term_to_search in st.session_state["pinterest_cache"]:
        pins = st.session_state["pinterest_cache"][term_to_search]

    if pins:
        st.markdown(f"#### ê²°ê³¼: `{term_to_search}`")
        c1, c2, c3 = st.columns(3)
        cols = [c1, c2, c3]
        for i, p in enumerate(pins):
            with cols[i % 3]:
                if p.get("img"):
                    link = p.get("link") or "https://www.pinterest.com/"
                    title = (p.get("title") or "").strip() or "Pinterest Pin"
                    st.markdown(
                        f"""
                        <a href="{link}" target="_blank" style="text-decoration:none;">
                            <img src="{p["img"]}" style="width:100%; border-radius:14px; margin-bottom:6px;" />
                        </a>
                        <div style="font-weight:700; margin-bottom:8px;">{title}</div>
                        """,
                        unsafe_allow_html=True,
                    )
                else:
                    st.info("ì´ë¯¸ì§€ URLì´ ì—†ëŠ” í•€ì´ì—ìš”.")
                with st.expander("ìƒì„¸"):
                    if p.get("description"):
                        st.write(p["description"])
                    if p.get("alt_text"):
                        st.caption(p["alt_text"])
                    if p.get("link"):
                        st.link_button("Pinterestì—ì„œ ì—´ê¸°", p["link"])

st.divider()

# -----------------------------
# ì¶”êµ¬ë¯¸ ë¦¬í¬íŠ¸ ìƒì„±
# -----------------------------
st.subheader("ğŸ§¾ ì¶”êµ¬ë¯¸ ë¶„ì„ & ë¦¬í¬íŠ¸")
can_run = 5 <= len(st.session_state["style_inputs"]["keywords"]) <= 10

colr1, colr2 = st.columns([1, 2])
with colr1:
    if st.button("âœ¨ ì¶”êµ¬ë¯¸ ë¶„ì„", use_container_width=True, disabled=not can_run):
        if not openai_key:
            st.warning("OpenAI API Keyë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ì¶”êµ¬ë¯¸ ë¦¬í¬íŠ¸ë¥¼ ìƒì„± ì¤‘..."):
                try:
                    sys_p, user_p = style_report_prompt(st.session_state["style_inputs"])
                    report, used_model = openai_json_with_fallback(
                        openai_key,
                        sys_p,
                        user_p,
                        model_candidates=model_candidates,
                        temperature=0.4,
                        timeout=90,
                    )
                    st.session_state["style_report"] = report
                    st.session_state["outfit_images"] = []
                    st.success(f"ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ! (ì‚¬ìš© ëª¨ë¸: {used_model})")
                except Exception as e:
                    st.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")

    st.caption("ì¡°ê±´: í‚¤ì›Œë“œ 5~10ê°œ ì„ íƒ")
with colr2:
    st.caption("â€» ì‚¬ì§„ ì—…ë¡œë“œê°€ ìˆì–´ë„, í˜„ì¬ëŠ” ì´ë¯¸ì§€ ì›ë³¸ì„ ì €ì¥í•˜ì§€ ì•Šê³  ë¶„ì„ ê²°ê³¼(í‚¤ì›Œë“œ/ê·¼ê±°)ë§Œ ì°¸ê³ í•©ë‹ˆë‹¤.")

if st.session_state.get("style_report"):
    r = st.session_state["style_report"]

    st.markdown(f"## ğŸ’ íƒ€ì…: **{r.get('type_name_ko','')}**  \n**{r.get('type_name_en','')}**")
    st.markdown(f"**í•œ ë¬¸ì¥ ì •ì²´ì„±:** {r.get('identity_one_liner','')}")
    st.markdown("**í•µì‹¬ í‚¤ì›Œë“œ:** " + ", ".join([f"`{k}`" for k in (r.get("core_keywords") or [])]))

    st.markdown("### ğŸ“Œ ë¯¸ë‹ˆ ë¦¬í¬íŠ¸")
    mini = r.get("mini_report", {}) or {}
    st.markdown(f"- ë¶„ìœ„ê¸° ìš”ì•½: {mini.get('mood_summary','')}")
    st.markdown(f"- íƒ€ì¸ ì¸ìƒ: {mini.get('impression','')}")

    best = mini.get("best_contexts") or []
    if best:
        st.markdown("- ì–´ìš¸ë¦¬ëŠ” ìƒí™©:")
        for x in best:
            st.markdown(f"  - {x}")
    else:
        st.caption("ì–´ìš¸ë¦¬ëŠ” ìƒí™© ì •ë³´ê°€ ì—†ì–´ìš”(ë¦¬í¬íŠ¸ ìƒì„± ì‹œ í¬í•¨ë˜ë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ê°•í™”í•´ë‘ì—ˆìŠµë‹ˆë‹¤).")

    st.markdown(f"- ê³¼ë„í•¨ ì£¼ì˜: {mini.get('watch_out','')}")
    st.markdown(f"- ìœ ì§€ ë‚œì´ë„: **{mini.get('maintenance_difficulty','')}**")

    if r.get("apply_strategy"):
        st.markdown("### ğŸ§© ì ìš© ì „ëµ")
        st.write(r["apply_strategy"])

    st.markdown("### ğŸª ì‹¤ì²œ ê°€ì´ë“œ (ë°©í–¥ì„±)")
    guide = r.get("practice_guide", {}) or {}
    m = guide.get("makeup", {}) or {}
    f = guide.get("fashion", {}) or {}
    b = guide.get("behavior_lifestyle", {}) or {}

    cga, cgb = st.columns(2)
    with cga:
        st.markdown("#### ğŸ’„ ë©”ì´í¬ì—…")
        st.markdown(f"- ë² ì´ìŠ¤: {m.get('base','')}")
        pts = m.get("points", {}) or {}
        st.markdown(f"- ëˆˆ: {pts.get('eyes','')}")
        st.markdown(f"- ì…ìˆ : {pts.get('lips','')}")
        st.markdown(f"- í”¼í•˜ë©´ ì¢‹ì€ ìš”ì†Œ: {m.get('avoid','')}")
    with cgb:
        st.markdown("#### ğŸ‘— íŒ¨ì…˜")
        st.markdown(f"- ì‹¤ë£¨ì—£: {f.get('silhouette','')}")

        palette = f.get("color_palette") or []
        avoid = f.get("avoid_colors") or []
        if palette:
            render_color_swatches(palette, title="ì¶”ì²œ ì»¬ëŸ¬ íŒ”ë ˆíŠ¸")
        if avoid:
            render_color_swatches(avoid, title="í”¼í•˜ë©´ ì¢‹ì€ ì»¬ëŸ¬")

        if f.get("top5_items"):
            st.markdown("- ê¸°ë³¸ ì•„ì´í…œ Top5:\n" + "\n".join([f"  - {x}" for x in f.get("top5_items", [])]))

    st.markdown("#### ğŸ§ í–‰ë™/ë¼ì´í”„ìŠ¤íƒ€ì¼")
    st.markdown(f"- ì œìŠ¤ì²˜/í†¤: {b.get('gesture_tone','')}")
    st.markdown(f"- ë§íˆ¬/ë§¤ë„ˆ: {b.get('speech_manner','')}")
    if b.get("daily_habits"):
        st.markdown("- ì‘ì€ ìŠµê´€:\n" + "\n".join([f"  - {x}" for x in b.get("daily_habits", [])]))

    st.divider()
    st.subheader("ğŸ§¥ ì˜ˆì‹œ ì½”ë”” (í…ìŠ¤íŠ¸ + ì‹œê°í™”)")

    outfit_examples = r.get("outfit_examples") or []
    if not outfit_examples:
        st.caption("ì˜ˆì‹œ ì½”ë””ê°€ ì—†ì–´ìš”(ë¦¬í¬íŠ¸ ìƒì„± í”„ë¡¬í”„íŠ¸ì—ì„œ ìƒì„±í•˜ë„ë¡ ìœ ë„í•´ë‘ì—ˆìŠµë‹ˆë‹¤).")
    else:
        for i, ex in enumerate(outfit_examples[:6], start=1):
            title = (ex or {}).get("title", f"ì½”ë”” {i}")
            items = (ex or {}).get("items", []) or []
            point = (ex or {}).get("point", "")
            refs = (ex or {}).get("palette_refs", []) or []

            with st.expander(f"{i}) {title}", expanded=(i == 1)):
                if items:
                    st.markdown("**êµ¬ì„± ì•„ì´í…œ**")
                    st.markdown("\n".join([f"- {it}" for it in items]))
                if point:
                    st.markdown(f"**í¬ì¸íŠ¸**: {point}")
                if refs:
                    st.caption("íŒ”ë ˆíŠ¸ ì°¸ê³ : " + ", ".join([str(x) for x in refs]))

        st.markdown("#### ğŸ¨ ì½”ë”” ì‹œê°í™”(ì´ë¯¸ì§€ ìƒì„±)")
        st.caption("ì„ íƒí•œ ì˜ˆì‹œ ì½”ë””ë¥¼ â€˜ë£©ë¶ ìŠ¤íƒ€ì¼â€™ë¡œ ê°„ë‹¨íˆ ì‹œê°í™”í•©ë‹ˆë‹¤. (ë¸Œëœë“œ ë¡œê³ /ë¬¸êµ¬ ì—†ì´)")

        titles = [(ex or {}).get("title", f"ì½”ë”” {i+1}") for i, ex in enumerate(outfit_examples[:6])]
        pick_idx = st.selectbox("ì‹œê°í™”í•  ì½”ë”” ì„ íƒ", list(range(len(titles))), format_func=lambda x: titles[x], index=0)

        if st.button("ğŸ–¼ï¸ ì„ íƒ ì½”ë””ë¥¼ ì´ë¯¸ì§€ë¡œ ë³´ê¸°", use_container_width=True):
            if not openai_key:
                st.warning("OpenAI API Keyë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            else:
                ex = outfit_examples[pick_idx]
                title = (ex or {}).get("title", "outfit")
                items = (ex or {}).get("items", []) or []
                point = (ex or {}).get("point", "")
                refs = (ex or {}).get("palette_refs", []) or []

                palette_map = {
                    c.get("name"): c.get("hex")
                    for c in (guide.get("fashion", {}) or {}).get("color_palette", [])
                    if isinstance(c, dict)
                }
                ref_hex = [f"{n}:{palette_map.get(n)}" for n in refs if palette_map.get(n)]

                img_prompt = (
                    "Fashion lookbook product photo, clean studio background, "
                    "full outfit laid out or worn by a faceless mannequin, no logos, no text.\n"
                    f"Outfit title: {title}\n"
                    f"Items: {', '.join(items) if items else 'N/A'}\n"
                    f"Styling point: {point}\n"
                    f"Color references: {', '.join(ref_hex) if ref_hex else ', '.join(refs)}\n"
                    "High quality, realistic, editorial style, minimal, soft lighting."
                )

                with st.spinner("ì½”ë”” ì´ë¯¸ì§€ë¥¼ ìƒì„± ì¤‘..."):
                    try:
                        b64_png, used_img_model = generate_outfit_image_with_fallback(
                            openai_key,
                            img_prompt,
                            image_model_candidates=image_model_candidates,
                            size=img_size,
                        )
                        st.session_state["outfit_images"].append(
                            {"title": title, "b64": b64_png, "prompt": img_prompt, "model": used_img_model}
                        )
                        st.success(f"ìƒì„± ì™„ë£Œ! (ì´ë¯¸ì§€ ëª¨ë¸: {used_img_model})")
                    except Exception as e:
                        st.error(f"ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {e}")

        if st.session_state.get("outfit_images"):
            st.markdown("#### ğŸ–¼ï¸ ìƒì„±ëœ ì½”ë”” ì´ë¯¸ì§€")
            cols = st.columns(3)
            for i, img in enumerate(st.session_state["outfit_images"][-6:]):
                with cols[i % 3]:
                    st.image(base64.b64decode(img["b64"]), caption=img.get("title", "outfit"), use_container_width=True)

st.divider()

# -----------------------------
# ì¶”êµ¬ë¯¸ ì±—ë´‡(ëŒ€í™”)
# -----------------------------
st.subheader("ğŸ’¬ ì¶”êµ¬ë¯¸ ì±—ë´‡ì—ê²Œ ë¬¼ì–´ë³´ê¸°")
st.caption("ì„ íƒ í‚¤ì›Œë“œ/ì…ë ¥ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ â€˜ê¸°ì¤€â€™ê³¼ â€˜ì‹¤ì²œ íŒâ€™ ìœ„ì£¼ë¡œ ë‹µí•´ìš”. (ë¸Œëœë“œ ì¶”ì²œ ì—†ìŒ)")

for m in st.session_state["style_messages"]:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

user_msg = st.chat_input("ì˜ˆ: 'ì„¸ë ¨+ì ˆì œ+ë¬´ì±„ìƒ‰ ëŠë‚Œì„ ìœ ì§€í•˜ë ¤ë©´ ë©”ì´í¬ì—…ì—ì„œ ë­˜ ì œì¼ ì¡°ì‹¬í•´ì•¼ í•´?'")
if user_msg:
    st.session_state["style_messages"].append({"role": "user", "content": user_msg})
    with st.chat_message("user"):
        st.markdown(user_msg)

    if not openai_key:
        with st.chat_message("assistant"):
            st.warning("ì‚¬ì´ë“œë°”ì— OpenAI API Keyë¥¼ ì…ë ¥í•˜ë©´ ì¶”êµ¬ë¯¸ ì±—ë´‡ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆì–´ìš”.")
    else:
        ctx = {
            "selected_keywords": st.session_state["style_inputs"].get("keywords", []),
            "text_like": st.session_state["style_inputs"].get("text_like", ""),
            "text_dislike": st.session_state["style_inputs"].get("text_dislike", ""),
            "text_constraints": st.session_state["style_inputs"].get("text_constraints", ""),
            "uploaded_image_analysis": st.session_state["style_inputs"].get("uploaded_image_analysis"),
            "style_report_summary": {
                "type_name": (st.session_state.get("style_report") or {}).get("type_name_ko"),
                "core_keywords": (st.session_state.get("style_report") or {}).get("core_keywords"),
            },
            "note": "ë¸Œëœë“œ/ì œí’ˆ ì¶”ì²œ ê¸ˆì§€. ë°©í–¥ì„±ê³¼ ê¸°ì¤€, ì²´í¬ë¦¬ìŠ¤íŠ¸ë§Œ.",
        }
        system_prompt = style_chat_system_prompt() + "\n\n[ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸]\n" + json.dumps(ctx, ensure_ascii=False)

        with st.chat_message("assistant"):
            try:
                assistant_text, used_model = openai_stream_chat_with_fallback(
                    openai_key,
                    system_prompt,
                    st.session_state["style_messages"],
                    model_candidates=model_candidates,
                    temperature=0.6,
                )
                st.session_state["style_messages"].append({"role": "assistant", "content": assistant_text})
                st.caption(f"ì‚¬ìš© ëª¨ë¸: {used_model}")
            except Exception as e:
                st.error(f"ì±—ë´‡ ì˜¤ë¥˜: {e}")
